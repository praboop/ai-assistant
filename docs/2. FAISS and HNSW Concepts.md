# üîç Understanding FAISS and HNSW

## üì¶ What is FAISS?

**FAISS** (*Facebook AI Similarity Search*) is an open-source library built by Meta AI to perform fast and scalable similarity search among dense vectors.

- Written in C++ with Python bindings.
- Efficient for billions of vectors.
- Used in semantic search, recommendation systems, document clustering, etc.

---

## üåê What is an Embedding?

An **embedding** is a high-dimensional numerical vector that represents the semantic meaning of text, images, or other data.

### üî¢ Example:

| Message                                | Embedding (vector)                         |
|----------------------------------------|---------------------------------------------|
| `"logout API documentation"`           | `[0.12, -0.45, ..., 0.67]` (768 dimensions) |
| `"how to sign out of the portal?"`     | `[0.13, -0.46, ..., 0.68]`                  |

> These two vectors will be close together in vector space because the meanings are similar.

---

## üöÄ What Does FAISS Do?

FAISS allows you to:

- Store high-dimensional embeddings.
- Perform **nearest neighbor search**.
- Use **approximate search** algorithms for speed and scalability.

---

## üèóÔ∏è What is HNSW?

**HNSW** = *Hierarchical Navigable Small World* graph, an efficient algorithm for **approximate nearest neighbor** (ANN) search.

### How HNSW Works:

- Builds a **multi-layer graph** where each node is a vector.
- Connects nodes to their nearest neighbors.
- Navigates from top sparse layers down to bottom dense layers to find close matches quickly.

---

## ‚öôÔ∏è Key Parameters in FAISS HNSW

```python
import faiss

dim = 768  # dimension of embeddings
M = 32     # number of neighbors per node

index = faiss.IndexHNSWFlat(dim, M, faiss.METRIC_INNER_PRODUCT)
index.hnsw.efConstruction = 200
index.hnsw.efSearch = 100
```

## ‚úÖ Benefits of FAISS + HNSW

| **Feature**         | **Benefit**                                                                 |
|---------------------|------------------------------------------------------------------------------|
| **Speed**           | Sub-millisecond search across millions of vectors                            |
| **Accuracy**        | High recall with adjustable `efSearch`                                       |
| **Scalability**     | Handles billions of vectors on CPU/GPU                                       |
| **Graph-based**     | HNSW structure provides efficient logarithmic search complexity              |
| **Cosine Similarity** | Inner product on normalized vectors yields cosine similarity                |
